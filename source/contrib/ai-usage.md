(contrib-ai-usage)=

# AI Usage Policy

We understand that many people are using AI coding tools such as ChatGPT, Claude, Copilot, Gemin, etc.

For Avogadro, code needs to be **correct** particularly for science-related topics. The force fields, the molecular dynamics, molecular surfaces, orbitals, etc. need substantial human intervention and review. Such tools can make mistakes in chemistry and numeric code, which require careful analysis and testing.

:::{important}
We reserve the right to reject contributions that seem like they were generated mostly by an ML tool, and code review will continue, particularly for any chemistry-specific or mathematical components.
:::

We are inspired in part by ["the five levels](https://www.danshapiro.com/blog/2026/01/the-five-levels-from-spicy-autocomplete-to-the-software-factory/) of use of AI coding tools, as described by Dan Shapiro.

0. **Spicy autocomplete**, aka original GitHub Copilot or copying and pasting snippets from ChatGPT.
1. The **coding intern**, writing unimportant snippets and boilerplate with full human review.
2. The **junior developer**, pair programming with the model but still reviewing every line.
3. The **developer**. Most code is generated by AI, and you take on the role of full-time code reviewer.
4. The **engineering team**. You're more of an engineering manager or product/program/project manager. You collaborate on specs and plans, the agents do the work.
5. The **dark software factory**, like a factory run by robots where the lights are out because robots don't need to see.

Our policy is that "**levels 0 and 1 are probably fine**" and further levels are not ðŸ›‘.

Several useful examples:
- using an AI tool to summarize code or provide examples (e.g., to help learn GLSL shaders) is fine, provided that any contributed code is implemented and reviewed by a human.
- discussing a high-level plan that's implemented by humans / level 0 seems okay, e.g., "can you help me plan mechanisms to provide a simple security sandbox for scripts. What are some pros and cons of the different approaches?"
- using various AI tools to *help* code review (e.g., [CodeRabbit](https://discuss.avogadro.cc/t/coderabbit-ai-reviews/7249) seems useful but does not replace human review)
- using an AI tool to guide debugging / bug fixing -- that's implemented by humans (e.g. "there seems to be a race condition in the properties dialog during vibration, can you suggest some possible solutions?")

If you have questions, please ask on [our forum](https://discuss.avogadro.cc/)
